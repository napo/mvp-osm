# -*- coding: utf-8 -*-
"""
Created on Sun Jul 24 5:26:00 2016

@author: Francesco Piazza
@author: Maurizio Napolitano
MIT License
"""

# NOTE: the SRID of the input DB is 4326
# NOTE: the SRID of the output DB is 3857

### Imports
import ConfigParser
import numpy as np
import os
import scipy as sc
import scipy.cluster.hierarchy
import scipy.spatial.distance
import sys
from datetime import datetime
from datetime import timedelta
from optparse import OptionParser
from pyspatialite import dbapi2 as db

### Global variables
TEMPLATECONFIG = "example.cfg"


### Classes


# Class to research pet locations generated by Most Valuable Player users
class MVP:
    # Sublass to store the maximum boundaries of the analysis grid
    class Gridbounds:
        # Coordinates of upper left bound
        min_x = None
        min_y = None
        # Coordinates of lower right bound
        max_x = None
        max_y = None

        # Constructor for class Gridbounds
        def __init__(self, min_x, min_y, max_x, max_y):
            self.min_x = float(min_x)
            self.min_y = float(min_y)
            self.max_x = float(max_x)
            self.max_y = float(max_y)

    # List of input database table names from which points and users are gathered
    # Suggested names are "osm_nodes", "osm_ways", "osm_relations"
    tables = ["osm_nodes", "osm_relations", "osm_ways"]

    # Path to input database
    indb = None

    # Path to output database
    outdb = None

    # Size of the time window in days (int)
    days = None

    # Grid resolution (meters? float)
    grid = None

    # Gridbounds object that stores the maximum boundaries of the analysis grid
    gridbounds = None

    # Spatial Reference System Identifier (SRID) for the input database
    epsg_in = None

    # Spatial Reference System Identifier (SRID) for the output database
    epsg_out = None

    # List of tags that indicate good local knowledge of the area
    goodtags = None

    # Constructor for class MVP
    def __init__(self, indb, outdb, days, grid, epsg_in, epsg_out, goodtags_filename):
        self.indb = indb
        self.outdb = outdb
        self.days = int(days)
        self.grid = float(grid)
        self.epsg_in = epsg_in
        self.epsg_out = epsg_out
        self.initGoodTags(goodtags_filename)
        self.initGridbounds()

    # Initializes both input and output db so that they're ready to update and query
    def initdb(self):
        cur = db.connect(self.outdb)
        rs = cur.execute('SELECT sqlite_version(), spatialite_version()')
        for row in rs:
            msg = "> System dependencies are OK. SQLite v%s Spatialite v%s" % (row[0], row[1])
            print msg
        print("> Database setup in progress, it may take a few minutes...")

        # Initialize the outdb for spatial operations
        sql = 'SELECT InitSpatialMetadata()'
        cur.execute(sql)

        # Table creation queries for outdb
        sql = '''CREATE TABLE points (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user STRING,
                timestamp INTEGER);'''
        cur.execute(sql)

        sql = '''SELECT AddGeometryColumn('points',
                'geometry', %s, 'POINT', 'XY');''' % self.epsg_out
        cur.execute(sql)

        sql = '''CREATE TABLE usersgrid (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user STRING,
                density INTEGER,
                activity INTEGER,
                class INTEGER default 0,
                gid INTEGER);'''
        cur.execute(sql)

        sql = '''SELECT AddGeometryColumn('usersgrid',
                'geometry', %s, 'POINT', 'XY');''' % self.epsg_out
        cur.execute(sql)

        sql = '''CREATE TABLE users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user STRING UNIQUE );'''
        cur.execute(sql)

        # creating a POLYGON table
        sql = '''CREATE TABLE grid (
            id INTEGER PRIMARY KEY AUTOINCREMENT)'''
        cur.execute(sql)

        sql = '''SELECT AddGeometryColumn('grid',
             'geometry', %s, 'POLYGON', 'XY')''' % self.epsg_out
        cur.execute(sql)

        sql = '''CREATE VIEW users_activity AS SELECT user,
                    ( Round(JulianDay(max(timestamp)))-(JulianDay(min(timestamp))) ) as activity
                    FROM points GROUP BY user;'''
        cur.execute(sql)

        sql = '''CREATE TABLE petlocations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            gid INTEGER,
            user STRING,
            density INTEGER,
            activity INTEGER,
            class INTEGER default 0);'''
        cur.execute(sql)

        sql = '''SELECT AddGeometryColumn('petlocations',
                'geometry', %s, 'POLYGON', 'XY');''' % self.epsg_out
        cur.execute(sql)

        # Initialize spatial indexes for all tables in all DBs
        self.initSpatialIndex(self.indb)
        self.initSpatialIndex(self.outdb)

        rs.close()
        cur.commit()
        cur.close()
        print "Database setup completed!"

    # Initializes the spatial index of given database (necessary for spatialite RTree queries on database)
    def initSpatialIndex(self, database):
        cur = db.connect(database)
        rs = cur.execute('SELECT * FROM geometry_columns')
        print("> Initializing Spatial Index for db %s..." % database)

        for row in rs:

            # Check if there's already a Spatial Index for the current table of current db
            if row[5] != 0:
                print("\tSpatial Index for table '%s' already ok!" % (row[0]))
            else:
                print("\tInitializing Spatial Index for table '%s', please wait..." % (row[0]))
                cur.execute("SELECT CreateSpatialIndex('%s', '%s');" % (row[0], row[1]))
                print("\tSpatial Index initialized!")
        rs.close()
        cur.close()

    # Get good tags from a multiline text file, sanitize them, init goodtags both here and in the indb
    # for query optimization
    def initGoodTags(self, filename):
        print("> Initializing good tags in the input database...")
        try:
            f = open(filename, 'r')
            self.goodtags = [item.strip() for item in f.readlines()]
            f.close()

            cur = db.connect(self.indb)

            # Check if there's an old version of the goodtags table and eventually drop it
            rs = cur.execute("SELECT sql FROM sqlite_master WHERE type = 'table' AND name = 'goodtags'")
            if rs.fetchall():
                cur.execute("DROP TABLE goodtags")
                print("Stale table goodtags of indb dropped")

            # Create and populate the goodtags table of indb
            cur.execute("CREATE TABLE goodtags (k TEXT PRIMARY KEY)")
            for tag in self.goodtags:
                sql = "INSERT INTO goodtags (k) VALUES (\'%s\')" % tag
                cur.execute(sql)

            print("Table goodtags of indb created and populated")

            cur.commit()
            cur.close()

        except OSError, e:
            print "Error " + e
            sys.exit(2)

    # Initializes the gridbounds for later operations
    def initGridbounds(self):
        print "> Initializing grid boundaries..."
        indb = db.connect(self.indb)
        incur = indb.cursor()

        # Gather the extreme boundaries of our node map (from indb), supposedly with INDB epsg
        sql = '''
        SELECT
            Min(MbrMinX(osm_nodes.geometry)) AS min_x,
            Min(MbrMinY(osm_nodes.geometry)) AS min_y,
            Max(MbrMaxX(osm_nodes.geometry)) AS max_x,
            Max(MbrMaxY(osm_nodes.geometry)) AS max_y
        FROM osm_nodes;
        '''
        rs = incur.execute(sql).fetchone()
        minx = rs[0]
        miny = rs[1]
        maxx = rs[2]
        maxy = rs[3]

        # Transform the boundaries in the new EPSG for outdb
        sql = 'SELECT ST_X(transform(MakePoint(%s,%s,%s),%s)),' % (minx, miny, self.epsg_in, self.epsg_out)
        sql += 'ST_Y(transform(MakePoint(%s,%s,%s),%s)),' % (minx, miny, self.epsg_in, self.epsg_out)
        sql += 'ST_X(transform(MakePoint(%s,%s,%s),%s)),' % (maxx, maxy, self.epsg_in, self.epsg_out)
        sql += 'ST_Y(transform(MakePoint(%s,%s,%s),%s));''' % (maxx, maxy, self.epsg_in, self.epsg_out)
        rs = incur.execute(sql).fetchone()

        # Initialize grid boundaries
        self.gridbounds = self.Gridbounds(rs[0], rs[1], rs[2], rs[3])

        # Close connections
        incur.close()
        indb.close()

    # The users table is populated with the IDs of those users who have been active for more than self.days days
    # and whose latest activity has been more recent than self.days days ago
    def importusers(self):
        print "> Importing prolific users who have been active recently..."
        delta_days = self.days
        indb = db.connect(self.indb)
        dbout = db.connect(self.outdb)
        incur = indb.cursor()
        outcur = dbout.cursor()

        # s is a flag to avoid repeating multiple executions of the user import (likely to be useless)
        s = 0

        for i in self.tables:
            # Define the time interval for analyzing users
            ago = ""
            if delta_days != 0:
                ago = datetime.today() - timedelta(delta_days)
                # Create a view that focuses on recently active users
                sql = '''
                CREATE VIEW users_lastdays AS
                        SELECT user, MAX(timestamp) AS tempo
                        FROM %s GROUP BY user;
                ''' % i
                incur.execute(sql)

            # Setup for the next SQL query to gather usernames
            if delta_days > 0:
                # This is the query if we have an analysis window larger than 0 days
                sql = '''
                SELECT DISTINCT(user)
                FROM users_lastdays
                WHERE tempo > "%s";
                ''' % str(ago)
            else:
                # This is the query if we have an analysis window smaller than 0 days
                sql = "SELECT distinct(user) FROM %s;" % i

            # Query execution
            rs = incur.execute(sql)
            r = rs.fetchall()

            # If it's the first time we try to initialize the users...
            if s == 0:
                # for each user in the resultset from previous query...
                for u in r:
                    user = u[0]
                    sql = "INSERT INTO users (user) VALUES (?);"
                    if user is not None:
                        # If the user is valid, insert it in the users table of the outdb
                        outcur.execute(sql, [user])
                        s += 1
            # If we have already inserted some users...
            else:
                # For each user in the resultset
                for u in r:
                    user = u[0]
                    # Search for that user among users we've previously inserted in outdb's users table
                    sql = "SELECT user FROM users WHERE user = (?);"  # user
                    rsu = list(outcur.execute(sql, [user]))
                    # If the user is new for the users table, insert it
                    if len(rsu) == 0:
                        sql = "INSERT INTO users (user) VALUES (?);"
                        outcur.execute(sql, [user])
                        s += 1

            # At the end, cleanup the indb if needed, by removing the view we had created before
            # This happens every time we finish analyzing a new table
            if delta_days > 0:
                sql = "DROP VIEW users_lastdays;"
                incur.execute(sql)

            # Print the operation results
            print("Users imported from table %s" % i)

        # Finalize and close connections
        outcur.close()
        incur.close()
        indb.commit()
        dbout.commit()
        indb.close()
        dbout.close()
        print("%d users imported" % s)

    # Insert a selection of nodes described by goodtags into the points table
    def insertptlnodes(self):
        print "> Searching the input database for nodes described by good tags..."
        indb = db.connect(self.indb)
        incur = indb.cursor()
        dbout = db.connect(self.outdb)
        outcur = dbout.cursor()
        for table in self.tables:
            sql = None

            if table == 'osm_nodes':
                # The following code isn't very efficient as is:
                #
                # w = ' in ('
                # for t in self.goodtags:
                #     t = "'" + t.rstrip() + "',"
                #     w += t
                # w += ")"
                # where_badtags = w.replace("(,", "(")
                # w = where_badtags.replace(",)", ")")
                #
                # sql = 'select X(transform(osm_nodes.Geometry,%s)) as x,' % (self.epsg_out)
                # sql += 'Y(transform(osm_nodes.Geometry,%s)) as y ' % (self.epsg_out)
                # sql += ', timestamp, user from osm_nodes '
                # sql += ' natural join %s_tags where %s_tags.k' % (table.rstrip('s'), table.rstrip('s'))
                # sql += w
                # sql += " GROUP BY user;"
                #
                # rs = incur.execute(sql)
                # for r in rs:
                #     if (r[2] is not None):
                #         p = "GeomFromText('POINT(%s %s)',%s)" % (r[0], r[1], self.epsg_out)
                #         sql = "INSERT INTO points (user, timestamp, geometry) "
                #         sql += "VALUES (?,?,%s)" % p  # % (r[3],r[2],p)
                #         outcur.execute(sql, (r[3], r[2]))
                # dbout.commit()
                #
                # Thus, I substitute the previous code with the following query, which has the purpose
                # of returning the correctly contextualized geometry of every node which is described by a goodtag,
                # along with the user who inserted that node and the timestamp of the last node edit
                sql = '''
                SELECT n.user AS user, n.timestamp as timestamp, AsText( Transform(n.Geometry, %s) ) as GeometryWKT
                FROM(
                    SELECT *
                    FROM osm_node_tags
                    WHERE k IN goodtags
                ) AS q
                INNER JOIN osm_nodes AS n
                WHERE q.node_id = n.node_id;
                ''' % self.epsg_out
            elif table == 'osm_ways':
                # This happens if tables other than osm_nodes are included in the set of tables to analyze
                # The original code (here in a working condition) was very inefficient, so I decided
                # to substitute it with some ludicrously efficient queries on the db
                # for t in self.goodtags:
                #    idname = table.replace("osm_", "").rstrip('s') + "_id"
                #    idname = idname.replace("relation", "rel")
                #    sql = 'select distinct(%s.%s) from %s' % (table, idname, table)
                #    sql += ' natural join %s_tags where ' % (table.rstrip('s'))
                #    sql += '%s_tags.k like "%s" ' % (table.rstrip('s'), t.rstrip())
                #    sql += " group by user"
                #    rs = incur.execute(sql)
                #    ids = rs.fetchall()
                #    for i in ids:
                #        sql = 'select distinct(osm_nodes.node_id), timestamp, user ' \
                #              'from osm_nodes natural join %s_refs where ' % (table.rstrip('s'))
                #        sql += '%s_refs.%s = %s' % (table.rstrip('s'), idname, i[0])
                #        rs = incur.execute(sql)
                #        idp = rs.fetchall()
                #        for ip in idp:
                #            sql = 'select X(transform(osm_nodes.Geometry,%s)) as x,' % (self.epsg_out)
                #            sql += 'Y(transform(osm_nodes.Geometry,%s)) as y, osm_nodes.timestamp ' % (self.epsg_out)
                #            sql += ' from osm_nodes'
                #            sql += ' where osm_nodes.node_id = %s' % ip[0]
                #            record = incur.execute(sql)
                #            v = record.fetchone()
                #            p = "GeomFromText('POINT(%s %s)',%s)" % (v[0], v[1], self.epsg_out)
                #            sql = "INSERT INTO points (user, timestamp, geometry) "
                #            sql += "VALUES (?,?,%s)" % p
                #            outcur.execute(sql, (ip[2], ip[1]))
                #            dbout.commit()
                #
                # The following query efficiently returns the correctly contextualized geometry of every node which is
                # part of a way described by a good tag, together with the name of the user who took care of the way
                # and the timestamp that indicates when the way was edited for the last time
                sql = '''
                SELECT q2.user AS user, q2.timestamp AS timestamp, AsText( Transform(n2.Geometry, %s)) AS GeometryWKT
                FROM (
                    SELECT q1.user AS user, q1.timestamp AS timestamp, r1.node_id AS node_id
                    FROM (
                        SELECT q.way_id as way_id, q.sub AS sub, t.user AS user, t.timestamp AS timestamp
                        FROM (
                            SELECT way_id, sub
                            FROM osm_way_tags
                            WHERE osm_way_tags.k IN goodtags
                        ) AS q
                        INNER JOIN osm_ways AS t
                        ON q.way_id = t.way_id
                    ) AS q1
                    INNER JOIN osm_way_refs AS r1
                    ON (q1.way_id=r1.way_id AND q1.sub=r1.sub)
                ) AS q2
                INNER JOIN osm_nodes AS n2
                ON q2.node_id = n2.node_id;
                ''' % self.epsg_out
            elif table == 'osm_relations':
                # The following query efficiently returns the correctly contextualized geometry of every node which is
                # part of a relation described by a good tag, together with the name of the user who took care of
                # the way and the timestamp that indicates when the relation was edited for the last time
                sql = '''
                SELECT user, timestamp, AsText( Transform(Geometry, %s) ) AS GeometryWKT
                FROM(
                    SELECT q2.user AS user, q2.timestamp AS timestamp, n2.Geometry AS Geometry
                    FROM(
                        SELECT r1.user AS user, r1.timestamp AS timestamp, q1.type AS type, q1.ref AS ref
                        FROM(
                            SELECT t.rel_id AS rel_id, r.type AS type, r.ref AS ref
                            FROM osm_relation_tags AS t
                            INNER JOIN osm_relation_refs AS r
                            ON (t.rel_id = r.rel_id
                            AND t.sub = r.sub)
                            WHERE k IN goodtags
                        ) AS q1
                        INNER JOIN osm_relations AS r1
                        ON q1.rel_id = r1.rel_id
                        WHERE q1.type = 'N'
                    ) AS q2
                    INNER JOIN osm_nodes AS n2
                    ON q2.ref = n2.node_id

                    UNION

                    SELECT q3.user AS user, q3.timestamp AS timestamp, n3.Geometry AS Geometry
                    FROM(
                        SELECT r1.user AS user, r1.timestamp AS timestamp, q1.type AS type, q1.ref AS ref
                        FROM(
                            SELECT t.rel_id AS rel_id, r.type AS type, r.ref AS ref
                            FROM osm_relation_tags AS t
                            INNER JOIN osm_relation_refs AS r
                            ON (t.rel_id = r.rel_id
                            AND t.sub = r.sub)
                            WHERE k IN goodtags
                        ) AS q1
                        INNER JOIN osm_relations AS r1
                        ON q1.rel_id = r1.rel_id
                        WHERE q1.type = 'W'
                    ) AS q3
                    INNER JOIN osm_way_refs AS r3
                    ON q3.ref = r3.way_id
                    INNER JOIN osm_nodes AS n3
                    ON r3.node_id = n3.node_id
                );
                ''' % self.epsg_out

            # Insert our precious data into the outdb
            rs = incur.execute(sql)
            for r in rs:
                p = "GeomFromText(\'%s\',%s)" % (r[2], self.epsg_out)
                sql = "INSERT INTO points (user, timestamp, geometry)"
                sql += "VALUES (?,?,%s);" % p  # % (r[0],r[1],p)
                outcur.execute(sql, (r[0], r[1]))
            dbout.commit()

            print("Nodes imported from table %s" % table)

        # Finalize and close connections
        outcur.close()
        dbout.close()
        incur.close()
        indb.close()

    # Creates a grid shaped geometrical structure in the outdb for further operations
    def creategrid(self):
        print "> Creating a grid structure in the output database..."

        # Connect to the output db
        dbout = db.connect(self.outdb)
        outcur = dbout.cursor()

        # Define the boundaries of the first square of the grid
        stepminx = self.gridbounds.min_x
        stepmaxx = self.gridbounds.min_x + self.grid
        stepminy = self.gridbounds.min_y
        stepmaxy = self.gridbounds.min_y + self.grid

        # Grid creation loop
        while True:
            # Create a polygon using the boundaries of a square on the grid and insert it in the 'grid' table in outdb
            p = "GeomFromText('POLYGON(("
            p += "%f %f, " % (stepminx, stepminy)
            p += "%f %f, " % (stepmaxx, stepminy)
            p += "%f %f, " % (stepmaxx, stepmaxy)
            p += "%f %f, " % (stepminx, stepmaxy)
            p += "%f %f" % (stepminx, stepminy)
            p += "))',%s)" % self.epsg_out
            sql = "INSERT INTO grid (geometry) "
            sql += "VALUES (%s);" % p
            outcur.execute(sql)

            # Update the boundaries
            if stepmaxx < self.gridbounds.max_x:
                # Step forward one column
                stepminx = stepmaxx
                stepmaxx += self.grid
            else:
                # Step forward one row
                stepminx = self.gridbounds.min_x
                stepmaxx = self.gridbounds.min_x + self.grid
                stepminy += self.grid
                stepmaxy += self.grid

                # Check if our cursor is out of all maximum boundaries
                if stepmaxy > self.gridbounds.max_y:
                    # Stop adding squares to the grid
                    break

        # Finalize changes and close connections
        dbout.commit()
        outcur.close()
        dbout.close()

    # Place user contributions into each grid cell if those users are likely to be MVPs
    def createusersgrid(self):
        print "> Creating user contributions grids..."

        # Connect to the output db
        dbout = db.connect(self.outdb)
        outcur = dbout.cursor()
        cursor = dbout.cursor()

        sql = '''
        SELECT
            count(pid) AS density,
            ( Round(JulianDay(max(timestamp))) - Round(JulianDay(min(timestamp))) ) AS activity,
            user,
            gid,
            centerWKT
        FROM (
            SELECT
                points.id AS pid,
                points.user AS user,
                points.timestamp AS timestamp,
                grid.id AS gid,
                AsWKT(Centroid(grid.geometry)) AS centerWKT
            FROM points, grid
            WHERE points.user IN (
                SELECT user FROM users_activity WHERE activity > %d
            )
            AND points.ROWID IN
            (
                SELECT ROWID
                FROM SpatialIndex
                WHERE f_table_name = 'points'
                AND search_frame = grid.geometry
            )
        )
        GROUP BY user, gid;
        ''' % self.days
        rs = cursor.execute(sql)

        # Data entry
        for r in rs:
            if r is not None:
                density = int(r[0])
                activity = int(r[1])
                if activity is None:
                    activity = 0
                user = r[2]
                gid = r[3]
                wkt = r[4]
                if user is not None:
                    p = "GeomFromText(\'%s\',%s)" % (wkt, self.epsg_out)
                    sql = "INSERT INTO usersgrid (user, density, activity, geometry, gid) "
                    sql += "VALUES (?,%d,%d,%s,%d);" % (density, activity, p, gid)
                    outcur.execute(sql, [user])

        # Finalize changes and close connections
        dbout.commit()
        cursor.close()
        outcur.close()
        dbout.close()

    # Cluster good user contributions from the usersgrid in contiguous groups of cells (classes).
    # Clusters will be retrievable from the usersgrid by looking at columns user and class.
    # Every user can have multiple clusters in different places.
    def clustergridgroup(self):
        dbout = db.connect(self.outdb)
        outcur = dbout.cursor()
        print("> Calculating user contribution clusters (gridsize is %s)..." % self.grid)

        # Fetch users from the usersgrid
        users = self.getusers()
        # For every user...
        for u in users:
            # Query all user contributions for user u in the usersgrid
            sql = '''
            SELECT id, ST_X(geometry), ST_Y(geometry)
            FROM usersgrid
            WHERE user=\"%s\";
            ''' % u
            rs = outcur.execute(sql)
            # result = array of cell centers where user u has been active
            result = []
            # ids = array of contribution IDs
            ids = []
            for r in rs:
                t = (r[1], r[2])
                result.append(t)
                ids.append(r[0])
            if len(result) > 1:
                # d = array of contribution coordinates
                d = np.array(result)

                # dist = distance matrix
                dist = scipy.spatial.distance.pdist(d, 'euclidean')

                # Z = linkage matrix
                z = sc.cluster.hierarchy.single(dist)

                # clustgroup = flat clusters from the hierarchical clustering defined by the linkage matrix Z
                # t is the threshold for clustering and it's the chosen grid size
                clustgroup = sc.cluster.hierarchy.fcluster(z, t=self.grid, criterion='distance')
                k = 0
                out = dbout.cursor()
                for c in clustgroup:
                    c = int(c)
                    idp = int(ids[k])
                    sql = '''
                    UPDATE usersgrid
                    SET class=%d
                    WHERE id=%d;
                    ''' % (c, idp)
                    out.execute(sql)
                    k += 1
                dbout.commit()
                out.close()
        outcur.close()

    # Fetch all distinct users from the usersgrid and return them in a list
    def getusers(self):
        dbout = db.connect(self.outdb)
        outcur = dbout.cursor()
        sql = "SELECT DISTINCT(user) FROM usersgrid;"
        users = list(outcur.execute(sql))
        outcur.close()
        return users

    # Populate the petlocations table
    def petlocations(self):
        print "> Calculating pet locations..."
        dbout = db.connect(self.outdb)
        outcur = dbout.cursor()

        sql = '''
        SELECT
            count(grid.id) AS gid,
            asText(CastToPolygon(gunion(grid.geometry))) AS geometry,
            usersgrid.class AS class,
            usersgrid.user AS user,
            max(usersgrid.activity) AS activity,
            max(usersgrid.density) AS density,
            geometrytype(gunion(grid.geometry)) AS tipo
        FROM
            usersgrid,
            grid
        where usersgrid.rowid IN
        (
            SELECT ROWID
            FROM SpatialIndex
            WHERE f_table_name = 'usersgrid'
            AND search_frame = grid.geometry
        )
        GROUP BY usersgrid.class, usersgrid.user
        ORDER BY user DESC;
        '''

        rs = outcur.execute(sql).fetchall()
        for r in rs:
            gid = r[0]
            geometry = r[1]
            clas = r[2]
            user = r[3]
            activity = r[4]
            density = r[5]
            g = "GeomFromText(\"%s\", %s)" % (geometry, self.epsg_out)

            sql = '''
            INSERT INTO petlocations (gid, geometry, class, user,activity,density)
            VALUES (?,%s,?,?,?,?);
            ''' % g
            outcur.execute(sql, [gid, clas, user, activity, density])
            dbout.commit()
        outcur.close()


### Script functions

# Main script logic flow
def execMVP(cmd):
    days = None
    epsg_in = None
    epsg_out = None
    outdb = None
    indb = None
    grid = None
    goodtags_filename = "conf/goodtags"

    # If the user asked to use a config file...
    if cmd.config:
        try:
            # Parse options from the config file
            parser = ConfigParser.ConfigParser()
            parser.readfp(open(cmd.config))
            goodtags_filename = parser.get("goodtags", "file")
            epsg_in = parser.get("config", "epsg_in")
            epsg_out = parser.get("config", "epsg_out")
            days = parser.get("config", "days")
            indb = parser.get("indb", "infile")
            outdb = parser.get("outdb", "outfile")

        except ConfigParser.NoOptionError, e:
            print "Error %s " % e
            sys.exit(2)

    # Set up parameters from user input
    if cmd.input:
        indb = cmd.input
    if cmd.output:
        outdb = cmd.output
    if cmd.tags:
        goodtags_filename = cmd.tags
    if cmd.epsgin:
        epsg_in = cmd.epsgin
    if cmd.epsgout:
        epsg_out = cmd.epsgout
    if cmd.grid:
        grid = cmd.grid
    if cmd.days:
        days = cmd.days

    # Default parameters
    if days is None:
        days = 180
    if grid is None:
        grid = 10000
    if epsg_in is None:
        epsg_in = "4326"
    if epsg_out is None:
        epsg_out = "3857"

    print("ExecMVP: %d %s %s %s %s %d %s" % (days, epsg_in, epsg_out, indb, outdb, grid, goodtags_filename))  # debug

    # Initialize the MVP object
    mu = MVP(indb, outdb, days, grid, epsg_in, epsg_out, goodtags_filename)

    # Initialize the DBs
    mu.initdb()
    # Create a grid in the outer DB (grid = grid resolution)
    mu.creategrid()
    # Import users from indb to outdb
    # The users table is populated with the IDs of those users who have recently been active
    mu.importusers()

    # Insert a list of nodes described by goodtags into the outdb points table
    mu.insertptlnodes()

    # Place user contributions into each grid cell if those users are likely to be MVPs
    mu.createusersgrid()

    # Cluster user contributions in contiguous groups of cells (classes)
    mu.clustergridgroup()

    # Populate the pet location table
    mu.petlocations()

    print("All operations were completed with success!")
    print("Enjoy your data in %s - Import it in QGIS to visualize it!" % cmd.output)
    print("(Use \'spatialite_osm_map\' to set up the undelying map from the original osm file)")


# CLI user interface
def main():
    usage = "usage: %prog [options]"
    parser = OptionParser(usage)
    parser.add_option("-c", "--config", action="store", dest="config",
                      help="fetch execution parameters from a configuration file")
    parser.add_option("-C", "--create", action="store_true", dest="create",
                      help="create a configuration file template - useful to create a new configuration file",
                      default=False)
    parser.add_option("-i", "--input", action="store", dest="input", help="input sqlite/spatialite database file *")
    parser.add_option("-o", "--output", action="store", dest="output", help="output sqlite/spatialite database file *")
    parser.add_option("-e", "--epsgin", action="store", dest="epsgin",
                      help="epsg metric (SRID) for the input database *")
    parser.add_option("-E", "--epsgout", action="store", dest="epsgout",
                      help="epsg metric (SRID) for the output database *")
    parser.add_option("-g", "--grid", action="store", dest="grid", help="grid size expressed in epsg unit *")
    parser.add_option("-d", "--days", action="store", dest="days", help="time window for analysis expressed in days *")
    parser.add_option("-t", "--tags", action="store", dest="tags",
                      help="txt file with the list of good tags to search *")
    (options, args) = parser.parse_args()
    if not options.create:
        if (options.input and options.output is not None) or (options.config is not None):
            execMVP(options)
        else:
            parser.print_help()
            print("* overrides options from the config file")
            print("Remember to use \'spatialite_osm_raw\' on the original osm file "
                  "to get an sqlite input file for this script!")
            sys.exit(0)
    else:
        try:
            f = open(os.getcwd() + os.path.sep + TEMPLATECONFIG, 'w')
            f.write("[config]\n")
            f.write("epsg_in: 4326\n")
            f.write("epsg_out: 3857\n")
            f.write("grid: 10000\n")
            f.write("days: 180\n")
            f.write("[goodtags]\n")
            f.write("file: conf/goodtags.txt\n")
            f.write("[indb]\n")
            f.write("infile:data/file.sqlite\n")
            f.write("[outdb]\n")
            f.write("outfile:data/mvposm.sqlite")
            f.close()
        except OSError, e:
            print "Error " + e
            sys.exit(2)


if __name__ == "__main__":
    main()
